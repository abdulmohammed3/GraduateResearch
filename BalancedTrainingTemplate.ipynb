{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "353ef16c-7909-4275-8a86-2bb5169c790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from platform import python_version\n",
    "import warnings\n",
    "import time\n",
    "import datetime as dt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import multiprocessing as mp\n",
    "import shutil\n",
    "\n",
    "from imblearn.keras import BalancedBatchGenerator\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "import psutil\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ade60864-c1db-40a3-a611-8eac370d62a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "img_size = 96\n",
    "epochs = 75\n",
    "batch_size = 32\n",
    "testsplit = .25\n",
    "targetx = 96\n",
    "targety = 96\n",
    "learning_rate = 0.0001\n",
    "classes = 7\n",
    "seed = 23\n",
    "print(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d18cae7-b559-4cb1-989d-328d4ea5ce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1124 images belonging to 7 classes.\n",
      "Found 370 images belonging to 7 classes.\n",
      "Found 358 images belonging to 7 classes.\n",
      "Found 1086 images belonging to 7 classes.\n",
      "Class 'angry' has 316 images.\n",
      "Class 'disgust' has 316 images.\n",
      "Class 'fear' has 316 images.\n",
      "Class 'happy' has 316 images.\n",
      "Class 'neutral' has 316 images.\n",
      "Class 'sad' has 315 images.\n",
      "Class 'surprise' has 315 images.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define two different ImageDataGenerators with their respective directories\n",
    "datagen1 = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        brightness_range=[0.9,1.1],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=testsplit,\n",
    "        preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "datagen2 = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        brightness_range=[0.9,1.1],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=testsplit,\n",
    "        preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_dir1 = 'KDEFMF/Male'\n",
    "train_dir2 = 'KDEFMF/Female'\n",
    "\n",
    "# Create two separate generators using different directories\n",
    "train_generator1 = datagen1.flow_from_directory(\n",
    "    train_dir1,\n",
    "    target_size=(targetx,targety),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=seed\n",
    ")\n",
    "validation_generator1 = datagen1.flow_from_directory(\n",
    "    'KDEFMF/Male',\n",
    "    target_size=(targetx,targety),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    ")\n",
    "validation_generator2 = datagen2.flow_from_directory(\n",
    "    'KDEFMF/Female',\n",
    "    target_size=(targetx,targety),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    ")\n",
    "\n",
    "train_generator2 = datagen2.flow_from_directory(\n",
    "    train_dir2,\n",
    "    target_size=(targetx,targety),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# Combine labels from both generators\n",
    "all_labels = list(train_generator1.classes) + list(train_generator2.classes)\n",
    "\n",
    "# Get class indices (assuming they are the same for both generators)\n",
    "class_indices = train_generator1.class_indices\n",
    "index_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts = Counter(all_labels)\n",
    "\n",
    "# Print the number of images per class\n",
    "for class_index, count in class_counts.items():\n",
    "    class_name = index_to_class[class_index]\n",
    "    print(f\"Class '{class_name}' has {count} images.\")\n",
    "    \n",
    "def combined_generator(gen1, gen2, num_batches):\n",
    "    while True:\n",
    "        try:\n",
    "            batch1_x, batch1_y = next(gen1)\n",
    "            batch2_x, batch2_y = next(gen2)\n",
    "\n",
    "            combined_x = np.concatenate((batch1_x, batch2_x), axis=0)\n",
    "            combined_y = np.concatenate((batch1_y, batch2_y), axis=0)\n",
    "\n",
    "            yield combined_x, combined_y\n",
    "        except StopIteration as e:\n",
    "            print(\"Generator exhausted or encountered an error:\", e)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b51feb8d-59df-4f5c-8f6c-eb68b495df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(targetx, targety, 3))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Custom Layers neccesarry to acheive high acurracy \n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten() (x)\n",
    "x = BatchNormalization()(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu',  kernel_initializer=glorot_uniform(seed),kernel_regularizer=regularizers.L2(0.001),activity_regularizer=regularizers.L2(1e-4), bias_initializer='zeros')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu',  kernel_initializer=glorot_uniform(seed),kernel_regularizer=regularizers.L2(0.001),activity_regularizer=regularizers.L2(1e-4), bias_initializer='zeros')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu',  kernel_initializer=glorot_uniform(seed),kernel_regularizer=regularizers.L2(0.001),activity_regularizer=regularizers.L2(1e-4), bias_initializer='zeros')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x=Dropout(0.3)(x)\n",
    "predictions = Dense(classes, activation='softmax', kernel_initializer='random_uniform', bias_initializer='zeros')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss = \"categorical_crossentropy\"\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4611629-4496-437d-814a-adc9d7f81373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the number of batches you want from each generator\n",
    "num_batches_per_gen = 100  # Adjust as needed\n",
    "\n",
    "# Use the combined generator for training\n",
    "combined_train_generator = combined_generator(train_generator1, train_generator2, num_batches_per_gen)\n",
    "\n",
    "# Use the combined generator for validation\n",
    "combined_validation_generator = combined_generator(validation_generator1, validation_generator2, num_batches_per_gen)\n",
    "\n",
    "\n",
    "steps_per_epoch = total_train_samples // (2 * 32)\n",
    "validation_steps = total_validation_samples // (2 * 32)\n",
    "\n",
    "# Ensure correct optimizer and loss function\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ensure ModelCheckpoint is correctly configured used for callback to save the best value based on val_accuracy\n",
    "checkpoint = ModelCheckpoint('SeqBalancedmodel.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    combined_train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=combined_validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f1ce7a-8387-4433-b483-acb848fcba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions and true labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for batch_x, batch_y in combined_validation_generator:\n",
    "    # Make predictions\n",
    "    predictions = model.predict(batch_x)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(batch_y, axis=1)\n",
    "    \n",
    "    # Append to lists\n",
    "    y_true.extend(true_classes)\n",
    "    y_pred.extend(predicted_classes)\n",
    "    \n",
    "    # Stop if you have processed the entire validation set\n",
    "    if len(y_true) >= total_validation_samples:\n",
    "        break\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, target_names=validation_generator1.class_indices.keys())\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfcf544-4d4c-4267-9546-ef91429c75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model =tf.keras.models.load_model('SeqBalancedmodel.keras')\n",
    "predictions = model.predict(validation_generator1, steps=len(validation_generator1))\n",
    "y = np.argmax(predictions, axis=1)\n",
    "\n",
    "print('Classification Report')\n",
    "cr = classification_report(y_true=validation_generator1.classes, y_pred=y, target_names=validation_generator1.class_indices)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199f0f2-be4e-4ac5-82ad-9cf93b4982f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model =tf.keras.models.load_model('SeqBalancedmodel.keras')\n",
    "predictions = model.predict(validation_generator2, steps=len(validation_generator2))\n",
    "y = np.argmax(predictions, axis=1)\n",
    "\n",
    "print('Classification Report')\n",
    "cr = classification_report(y_true=validation_generator2.classes, y_pred=y, target_names=validation_generator2.class_indices)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46390f2-05c6-48aa-a3bf-863d37ba506d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
